# Définition de l'input pour Logstash
input {
  # Utilisation du plugin beats pour recevoir les logs envoyés par Filebeat
  beats {
    port => 5044                         # Écoute sur le port 5044 pour les connexions Filebeat
  }
}

# Section de filtrage pour transformer et enrichir les données des logs
filter {
  # Utilisation du plugin grok pour extraire des champs spécifiques à partir du message brut
  grok {
    match => {
      "message" => [
        # Exemple de log attendu :
        # "WARNING 2025-02-21 15:08:54,226 log 11 139874183469880 Unauthorized: ..."
        "^%{LOGLEVEL:loglevel} %{TIMESTAMP_ISO8601:timestamp} %{DATA:logger} %{NUMBER:pid} (?:%{NUMBER:thread}|%{DATA:thread}) %{GREEDYDATA:log_message}"
      ]
    }
  }

  # Utilisation du plugin date pour convertir le champ timestamp extrait en @timestamp
  date {
    match => [ "timestamp", "ISO8601" ]    # Indique que le format attendu pour le champ timestamp est ISO8601
    timezone => "Europe/Paris"             # Définit le fuseau horaire pour l'interprétation du timestamp
    remove_field => [ "timestamp" ]        # Supprime le champ timestamp d'origine après conversion
  }
}

# Définition de la sortie pour Logstash
output {
  # Envoie des logs transformés vers Elasticsearch
  elasticsearch {
    hosts => ["${ELASTICSEARCH_URL}"]      # Utilise l'URL d'Elasticsearch définie dans les variables d'environnement
    index => "logs-%{+YYYY.MM.dd}"          # Crée un index journalier nommé "logs-YYYY.MM.dd" selon la date
    user => "${ELASTICSEARCH_LOGSTASH_USERNAME}"  # Nom d'utilisateur pour l'authentification auprès d'Elasticsearch
    password => "${ELASTICSEARCH_LOGSTASH_PASSWORD}"  # Mot de passe pour l'authentification
  }
  
  # Affiche aussi les logs sur la console pour faciliter le débogage
  # stdout { codec => rubydebug }            # Utilise le codec rubydebug pour une sortie lisible dans la console
}
